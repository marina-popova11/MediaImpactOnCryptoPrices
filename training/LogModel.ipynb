{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5141ca46-d405-4e04-9095-3e0f0db51d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn nltk joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5483a889-adf4-4bc7-8d12-26db71fe4fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Train_data shape:  (74682, 4)\n",
      "      0            1         2  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                   3  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "row 0: [np.int64(2401), 'Borderlands', 'Positive', 'im getting on borderlands and i will murder you all ,']\n",
      "row 1: [np.int64(2401), 'Borderlands', 'Positive', 'I am coming to the borders and I will kill you all,']\n",
      "row 2: [np.int64(2401), 'Borderlands', 'Positive', 'im getting on borderlands and i will kill you all,']\n",
      "sentiment\n",
      "Negative      22542\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: count, dtype: int64\n",
      "['col_0', 'col_1', 'sentiment', 'text', 'cleaned_data']\n",
      "TF-IDF matrix shape: (74682, 5000)\n",
      "Train Accuracy: 0.7305\n",
      "<function classification_report at 0x000002F167E66840> ['Positive' 'Positive' 'Positive' ... 'Negative' 'Positive' 'Negative']\n",
      "save\n",
      "(999, 4)\n",
      "['3364', 'Facebook', 'Irrelevant', 'I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom’s great auntie as ‘Hayley can’t get out of bed’ and told to his grandma, who now thinks I’m a lazy, terrible person 🤣']\n",
      "['col_0', 'col_1', 'sentiment', 'text', 'cleaned_text']\n",
      "Accuracy: 0.7928 (79.28)\n",
      "Precision: 0.7955\n",
      "Recall: 0.7928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.71      0.81      0.75       171\n",
      "    Negative       0.81      0.81      0.81       266\n",
      "     Neutral       0.82      0.74      0.78       285\n",
      "    Positive       0.81      0.82      0.82       277\n",
      "\n",
      "    accuracy                           0.79       999\n",
      "   macro avg       0.79      0.79      0.79       999\n",
      "weighted avg       0.80      0.79      0.79       999\n",
      "\n",
      "Analyze: \n",
      "\n",
      "A ban for Battlefield 4 player ItzAwwZy has occurred SEE DETAILS: bf4db.com/play... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player YourDaddyyyyyy has occurred SEE DETAILS: bf4db.co... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player rifqipratama has occurred SEE DETAILS: bf4db.com/... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player SasoByte has occurred SEE DETAILS: bf4db.com/play... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player Gariblak has occurred SEE DETAILS: bf4db.com/play... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "Yo @NBA2K fuck your fake ass garbage ass game... -> Predict: Negative, True: Negative, Confidence: 0.9929\n",
      "@NBA2K @2KSupport @LD2K @Beluba  can y’all please fix this !!! pic.twitter.com/y... -> Predict: Negative, True: Negative, Confidence: 0.9921\n",
      "It’s ridiculous and embarrassing how unplayable @NBA2K is when there’s any form ... -> Predict: Negative, True: Negative, Confidence: 0.9899\n",
      "@EAMaddenNFL servers down?... -> Predict: Negative, True: Negative, Confidence: 0.9888\n",
      "same game smh 🤦🏾‍♂️ @NBA2K #NBA2K21Demo #NBA2K21 pic.twitter.com/QRCV7AmeQi... -> Predict: Negative, True: Negative, Confidence: 0.9882\n",
      "Wilson 💛... -> Predict: Neutral, True: Irrelevant, Confidence: 0.2791\n",
      "Not this again... -> Predict: Neutral, True: Negative, Confidence: 0.2791\n",
      "Mori😻😻😻😻... -> Predict: Neutral, True: Neutral, Confidence: 0.2791\n",
      "Trippy #GhostReconBreakpoint\n",
      "\n",
      "store.playstation.com/#!/en-us/tid=C… https://t.co... -> Predict: Neutral, True: Neutral, Confidence: 0.2791\n",
      "Aiiight 💪... -> Predict: Neutral, True: Neutral, Confidence: 0.2791\n",
      "Tempting 😖... -> Predict: Neutral, True: Positive, Confidence: 0.2791\n",
      "This is so upsetting 😭... -> Predict: Neutral, True: Negative, Confidence: 0.2791\n",
      "How many of you have bought the season 6 battle pass for Modern war zone? Person... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.3004\n",
      "I’ll never understand how people enjoy overwatch... -> Predict: Irrelevant, True: Negative, Confidence: 0.3022\n",
      "oooooh shit i think my motherboard is already compatible... -> Predict: Neutral, True: Positive, Confidence: 0.3134\n",
      "Class Irrelevant: 195 examples (19.5%)\n",
      "Class Negative: 266 examples (26.6%)\n",
      "Class Neutral: 258 examples (25.8%)\n",
      "Class Positive: 280 examples (28.0%)\n",
      "\n",
      "\n",
      "BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine… -> Neutral\n",
      "@Microsoft Why do I pay for WORD when it functions so poorly on my @SamsungUS Chromebook? 🙄 -> Negative\n",
      "CSGO matchmaking is so full of closet hacking, it's a truly awful game. -> Negative\n",
      "Now the President is slapping Americans in the face that he really did commit an unlawful act after his  acquittal! From Discover on Google vanityfair.com/news/2020/02/t… -> Neutral\n",
      "Hi @EAHelp I’ve had Madeleine McCann in my cellar for the past 13 years and the little sneaky thing just escaped whilst I was loading up some fifa points, she took my card and I’m having to use my paypal account but it isn’t working, can you help me resolve it please? -> Negative\n",
      "Thank you @EAMaddenNFL!! \n",
      "\n",
      "New TE Austin Hooper in the ORANGE & BROWN!! \n",
      "\n",
      "#Browns | @AustinHooper18 \n",
      "\n",
      " pic.twitter.com/GRg4xzFKOn -> Positive\n",
      "Rocket League, Sea of Thieves or Rainbow Six: Siege🤔? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow -> Positive\n",
      "my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao -> Positive\n",
      "FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q -> Negative\n",
      "The professional dota 2 scene is fucking exploding and I completely welcome it.\n",
      "\n",
      "Get the garbage out. -> Irrelevant\n",
      "Itching to assassinate \n",
      "\n",
      "#TCCGif #AssassinsCreedBlackFlag #AssassinsCreed #TheCapturedCollective pic.twitter.com/vv8MOGtCjw -> Irrelevant\n",
      "@FredTJoseph hey fred, Comcast cut the cable and now Verizon stays calling me to shut that too pic.twitter.com/CPWSrmueDg -> Negative\n",
      "CSGO WIngman (Im Silver dont bully) twitch.tv/lprezh -> Neutral\n",
      "@NBA2K game sucks... down by 2 with 38 seconds left and my team intentionally fouls -> Negative\n",
      "Congrats to the NVIDIA NeMo team for the 1.0.0 release candidate!\n",
      "Really excited to see NeMo embracing Hydra as the way to take control over the configuration madness that is machine learning! :) -> Positive\n",
      "yeah and it’s fun -> Positive\n",
      "fuck my life 😆 -> Negative\n",
      "happy birthday red dead redemption that shit changed my life what a crazy experience -> Irrelevant\n",
      "What does that say about Microsoft hardware & software security - The Man gets hacked -> Negative\n",
      "The new @CallofDuty for ps5 is 🔥🔥🔥🔥\n",
      "Oh God 😭😍 -> Negative\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from download import preprocess_text\n",
    "\n",
    "test_data = pd.read_csv(\"twitter_validation.csv\")\n",
    "print(test_data.shape)\n",
    "print(test_data.columns.tolist())\n",
    "test_data.columns = [f\"col_{i}\" for i in range(test_data.shape[1])]\n",
    "test_data = test_data.rename(columns={\n",
    "    f\"col_{3}\": \"text\",\n",
    "    f\"col_{2}\": \"sentiment\"\n",
    "})\n",
    "\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "print(test_data.columns.tolist())\n",
    "\n",
    "\n",
    "loaded_model = joblib.load(\"sentiment_model.pkl\")\n",
    "loaded_tfidf = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "X_test = loaded_tfidf.transform(test_data[\"cleaned_text\"])\n",
    "\n",
    "test_pred = loaded_model.predict(X_test)\n",
    "test_prob = loaded_model.predict_proba(X_test)\n",
    "\n",
    "test_data[\"predicted_sentiment\"] = test_pred\n",
    "test_data[\"prediction_confidence\"] = np.max(test_prob, axis=1)\n",
    "\n",
    "def model_evaluation(y_true, y_pred, model_name=\"Sentiment Model\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f})\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(classification_report(y_true, y_pred , target_names=['Irrelevant', 'Negative', 'Neutral', 'Positive'], zero_division=0))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "def analyze_predictions(df, text_col=\"text\", pred_col='predicted_sentiment', true_col=None, confidence_col='prediction_confidence'):\n",
    "    print(\"Analyze: \\n\")\n",
    "    top_confident = df.nlargest(10, confidence_col)\n",
    "    for id, row in top_confident.iterrows():\n",
    "        true_labels = row[true_col] if true_col else \"N/A\"\n",
    "        print(f\"{row[text_col][:80]}... -> Predict: {row[pred_col]}, \"\n",
    "              f\"True: {true_labels}, Confidence: {row[confidence_col]:.4f}\")\n",
    "\n",
    "    low_confident = df.nsmallest(10, confidence_col)\n",
    "    for idx, row in low_confident.iterrows():\n",
    "        true_labels = row[true_col] if true_col else \"N/A\"\n",
    "        print(f\"{row[text_col][:80]}... -> Predict: {row[pred_col]}, \"\n",
    "              f\"True: {true_labels}, Confidence: {row[confidence_col]:.4f}\")\n",
    "\n",
    "    pred_distribution = df[pred_col].value_counts().sort_index()\n",
    "    for class_label, count in pred_distribution.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"Class {class_label}: {count} examples ({percentage:.1f}%)\")\n",
    "\n",
    "if \"sentiment\" in test_data.columns:\n",
    "    true_labels = test_data[\"sentiment\"]\n",
    "    metrics = model_evaluation(true_labels, test_pred)\n",
    "    analyze_predictions(test_data, true_col=\"sentiment\")\n",
    "else:\n",
    "    print(test_data[\"prediction_confidence\"].describe())\n",
    "    analyze_predictions(test_data)\n",
    "\n",
    "print(\"\\n\")\n",
    "for index, row in test_data.head(20).iterrows():\n",
    "    print(f\"{row['text']} -> {row['predicted_sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b5833-d7cd-49ed-ad13-f667fbd90e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_data = pd.read_csv(\"twitter_training.csv\", header=None)\n",
    "print(\"Train_data shape: \", train_data.shape)\n",
    "print(train_data.head())\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"row {i}: {train_data.iloc[i].tolist()}\")\n",
    "text_column = 3\n",
    "sentiment_column = 2\n",
    "train_data.columns = [f\"col_{i}\" for i in range(train_data.shape[1])]\n",
    "train_data = train_data.rename(columns={\n",
    "    f\"col_{text_column}\": \"text\",\n",
    "    f\"col_{sentiment_column}\": \"sentiment\"\n",
    "})\n",
    "\n",
    "print(train_data[\"sentiment\"].value_counts())\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text)\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, flags=re.I|re.A)\n",
    "    text = text.lower().strip()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_data[\"cleaned_data\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "print(train_data.columns.tolist())\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train_data[\"cleaned_data\"])\n",
    "y_train = train_data[\"sentiment\"]\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X_train.shape}\")\n",
    "\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(classification_report, train_predictions)\n",
    "\n",
    "joblib.dump(model, 'sentiment_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "print(\"save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb00648-382a-4588-b5d0-d34679688e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
