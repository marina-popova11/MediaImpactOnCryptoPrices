{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5141ca46-d405-4e04-9095-3e0f0db51d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn nltk joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5483a889-adf4-4bc7-8d12-26db71fe4fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\peche\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Train_data shape:  (74682, 4)\n",
      "      0            1         2  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                   3  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "row 0: [np.int64(2401), 'Borderlands', 'Positive', 'im getting on borderlands and i will murder you all ,']\n",
      "row 1: [np.int64(2401), 'Borderlands', 'Positive', 'I am coming to the borders and I will kill you all,']\n",
      "row 2: [np.int64(2401), 'Borderlands', 'Positive', 'im getting on borderlands and i will kill you all,']\n",
      "sentiment\n",
      "Negative      22542\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: count, dtype: int64\n",
      "['col_0', 'col_1', 'sentiment', 'text', 'cleaned_data']\n",
      "TF-IDF matrix shape: (74682, 5000)\n",
      "Train Accuracy: 0.7305\n",
      "<function classification_report at 0x000002F167E66840> ['Positive' 'Positive' 'Positive' ... 'Negative' 'Positive' 'Negative']\n",
      "save\n",
      "(999, 4)\n",
      "['3364', 'Facebook', 'Irrelevant', 'I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tomâ€™s great auntie as â€˜Hayley canâ€™t get out of bedâ€™ and told to his grandma, who now thinks Iâ€™m a lazy, terrible person ðŸ¤£']\n",
      "['col_0', 'col_1', 'sentiment', 'text', 'cleaned_text']\n",
      "Accuracy: 0.7928 (79.28)\n",
      "Precision: 0.7955\n",
      "Recall: 0.7928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.71      0.81      0.75       171\n",
      "    Negative       0.81      0.81      0.81       266\n",
      "     Neutral       0.82      0.74      0.78       285\n",
      "    Positive       0.81      0.82      0.82       277\n",
      "\n",
      "    accuracy                           0.79       999\n",
      "   macro avg       0.79      0.79      0.79       999\n",
      "weighted avg       0.80      0.79      0.79       999\n",
      "\n",
      "Analyze: \n",
      "\n",
      "A ban for Battlefield 4 player ItzAwwZy has occurred SEE DETAILS: bf4db.com/play... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player YourDaddyyyyyy has occurred SEE DETAILS: bf4db.co... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player rifqipratama has occurred SEE DETAILS: bf4db.com/... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player SasoByte has occurred SEE DETAILS: bf4db.com/play... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "A ban for Battlefield 4 player Gariblak has occurred SEE DETAILS: bf4db.com/play... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.9983\n",
      "Yo @NBA2K fuck your fake ass garbage ass game... -> Predict: Negative, True: Negative, Confidence: 0.9929\n",
      "@NBA2K @2KSupport @LD2K @Beluba  can yâ€™all please fix this !!! pic.twitter.com/y... -> Predict: Negative, True: Negative, Confidence: 0.9921\n",
      "Itâ€™s ridiculous and embarrassing how unplayable @NBA2K is when thereâ€™s any form ... -> Predict: Negative, True: Negative, Confidence: 0.9899\n",
      "@EAMaddenNFL servers down?... -> Predict: Negative, True: Negative, Confidence: 0.9888\n",
      "same game smh ðŸ¤¦ðŸ¾â€â™‚ï¸ @NBA2K #NBA2K21Demo #NBA2K21 pic.twitter.com/QRCV7AmeQi... -> Predict: Negative, True: Negative, Confidence: 0.9882\n",
      "Wilson ðŸ’›... -> Predict: Neutral, True: Irrelevant, Confidence: 0.2791\n",
      "Not this again... -> Predict: Neutral, True: Negative, Confidence: 0.2791\n",
      "MoriðŸ˜»ðŸ˜»ðŸ˜»ðŸ˜»... -> Predict: Neutral, True: Neutral, Confidence: 0.2791\n",
      "Trippy #GhostReconBreakpoint\n",
      "\n",
      "store.playstation.com/#!/en-us/tid=Câ€¦ https://t.co... -> Predict: Neutral, True: Neutral, Confidence: 0.2791\n",
      "Aiiight ðŸ’ª... -> Predict: Neutral, True: Neutral, Confidence: 0.2791\n",
      "Tempting ðŸ˜–... -> Predict: Neutral, True: Positive, Confidence: 0.2791\n",
      "This is so upsetting ðŸ˜­... -> Predict: Neutral, True: Negative, Confidence: 0.2791\n",
      "How many of you have bought the season 6 battle pass for Modern war zone? Person... -> Predict: Irrelevant, True: Irrelevant, Confidence: 0.3004\n",
      "Iâ€™ll never understand how people enjoy overwatch... -> Predict: Irrelevant, True: Negative, Confidence: 0.3022\n",
      "oooooh shit i think my motherboard is already compatible... -> Predict: Neutral, True: Positive, Confidence: 0.3134\n",
      "Class Irrelevant: 195 examples (19.5%)\n",
      "Class Negative: 266 examples (26.6%)\n",
      "Class Neutral: 258 examples (25.8%)\n",
      "Class Positive: 280 examples (28.0%)\n",
      "\n",
      "\n",
      "BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busineâ€¦ -> Neutral\n",
      "@Microsoft Why do I pay for WORD when it functions so poorly on my @SamsungUS Chromebook? ðŸ™„ -> Negative\n",
      "CSGO matchmaking is so full of closet hacking, it's a truly awful game. -> Negative\n",
      "Now the President is slapping Americans in the face that he really did commit an unlawful act after his  acquittal! From Discover on Google vanityfair.com/news/2020/02/tâ€¦ -> Neutral\n",
      "Hi @EAHelp Iâ€™ve had Madeleine McCann in my cellar for the past 13 years and the little sneaky thing just escaped whilst I was loading up some fifa points, she took my card and Iâ€™m having to use my paypal account but it isnâ€™t working, can you help me resolve it please? -> Negative\n",
      "Thank you @EAMaddenNFL!! \n",
      "\n",
      "New TE Austin Hooper in the ORANGE & BROWN!! \n",
      "\n",
      "#Browns | @AustinHooper18 \n",
      "\n",
      " pic.twitter.com/GRg4xzFKOn -> Positive\n",
      "Rocket League, Sea of Thieves or Rainbow Six: SiegeðŸ¤”? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow -> Positive\n",
      "my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao -> Positive\n",
      "FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q -> Negative\n",
      "The professional dota 2 scene is fucking exploding and I completely welcome it.\n",
      "\n",
      "Get the garbage out. -> Irrelevant\n",
      "Itching to assassinate \n",
      "\n",
      "#TCCGif #AssassinsCreedBlackFlag #AssassinsCreed #TheCapturedCollective pic.twitter.com/vv8MOGtCjw -> Irrelevant\n",
      "@FredTJoseph hey fred, Comcast cut the cable and now Verizon stays calling me to shut that too pic.twitter.com/CPWSrmueDg -> Negative\n",
      "CSGO WIngman (Im Silver dont bully) twitch.tv/lprezh -> Neutral\n",
      "@NBA2K game sucks... down by 2 with 38 seconds left and my team intentionally fouls -> Negative\n",
      "Congrats to the NVIDIA NeMo team for the 1.0.0 release candidate!\n",
      "Really excited to see NeMo embracing Hydra as the way to take control over the configuration madness that is machine learning! :) -> Positive\n",
      "yeah and itâ€™s fun -> Positive\n",
      "fuck my life ðŸ˜† -> Negative\n",
      "happy birthday red dead redemption that shit changed my life what a crazy experience -> Irrelevant\n",
      "What does that say about Microsoft hardware & software security - The Man gets hacked -> Negative\n",
      "The new @CallofDuty for ps5 is ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥\n",
      "Oh God ðŸ˜­ðŸ˜ -> Negative\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from download import preprocess_text\n",
    "\n",
    "test_data = pd.read_csv(\"twitter_validation.csv\")\n",
    "print(test_data.shape)\n",
    "print(test_data.columns.tolist())\n",
    "test_data.columns = [f\"col_{i}\" for i in range(test_data.shape[1])]\n",
    "test_data = test_data.rename(columns={\n",
    "    f\"col_{3}\": \"text\",\n",
    "    f\"col_{2}\": \"sentiment\"\n",
    "})\n",
    "\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)\n",
    "print(test_data.columns.tolist())\n",
    "\n",
    "\n",
    "loaded_model = joblib.load(\"sentiment_model.pkl\")\n",
    "loaded_tfidf = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "X_test = loaded_tfidf.transform(test_data[\"cleaned_text\"])\n",
    "\n",
    "test_pred = loaded_model.predict(X_test)\n",
    "test_prob = loaded_model.predict_proba(X_test)\n",
    "\n",
    "test_data[\"predicted_sentiment\"] = test_pred\n",
    "test_data[\"prediction_confidence\"] = np.max(test_prob, axis=1)\n",
    "\n",
    "def model_evaluation(y_true, y_pred, model_name=\"Sentiment Model\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f})\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(classification_report(y_true, y_pred , target_names=['Irrelevant', 'Negative', 'Neutral', 'Positive'], zero_division=0))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "def analyze_predictions(df, text_col=\"text\", pred_col='predicted_sentiment', true_col=None, confidence_col='prediction_confidence'):\n",
    "    print(\"Analyze: \\n\")\n",
    "    top_confident = df.nlargest(10, confidence_col)\n",
    "    for id, row in top_confident.iterrows():\n",
    "        true_labels = row[true_col] if true_col else \"N/A\"\n",
    "        print(f\"{row[text_col][:80]}... -> Predict: {row[pred_col]}, \"\n",
    "              f\"True: {true_labels}, Confidence: {row[confidence_col]:.4f}\")\n",
    "\n",
    "    low_confident = df.nsmallest(10, confidence_col)\n",
    "    for idx, row in low_confident.iterrows():\n",
    "        true_labels = row[true_col] if true_col else \"N/A\"\n",
    "        print(f\"{row[text_col][:80]}... -> Predict: {row[pred_col]}, \"\n",
    "              f\"True: {true_labels}, Confidence: {row[confidence_col]:.4f}\")\n",
    "\n",
    "    pred_distribution = df[pred_col].value_counts().sort_index()\n",
    "    for class_label, count in pred_distribution.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"Class {class_label}: {count} examples ({percentage:.1f}%)\")\n",
    "\n",
    "if \"sentiment\" in test_data.columns:\n",
    "    true_labels = test_data[\"sentiment\"]\n",
    "    metrics = model_evaluation(true_labels, test_pred)\n",
    "    analyze_predictions(test_data, true_col=\"sentiment\")\n",
    "else:\n",
    "    print(test_data[\"prediction_confidence\"].describe())\n",
    "    analyze_predictions(test_data)\n",
    "\n",
    "print(\"\\n\")\n",
    "for index, row in test_data.head(20).iterrows():\n",
    "    print(f\"{row['text']} -> {row['predicted_sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b5833-d7cd-49ed-ad13-f667fbd90e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_data = pd.read_csv(\"twitter_training.csv\", header=None)\n",
    "print(\"Train_data shape: \", train_data.shape)\n",
    "print(train_data.head())\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"row {i}: {train_data.iloc[i].tolist()}\")\n",
    "text_column = 3\n",
    "sentiment_column = 2\n",
    "train_data.columns = [f\"col_{i}\" for i in range(train_data.shape[1])]\n",
    "train_data = train_data.rename(columns={\n",
    "    f\"col_{text_column}\": \"text\",\n",
    "    f\"col_{sentiment_column}\": \"sentiment\"\n",
    "})\n",
    "\n",
    "print(train_data[\"sentiment\"].value_counts())\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text)\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, flags=re.I|re.A)\n",
    "    text = text.lower().strip()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_data[\"cleaned_data\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "print(train_data.columns.tolist())\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(train_data[\"cleaned_data\"])\n",
    "y_train = train_data[\"sentiment\"]\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X_train.shape}\")\n",
    "\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(classification_report, train_predictions)\n",
    "\n",
    "joblib.dump(model, 'sentiment_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "print(\"save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb00648-382a-4588-b5d0-d34679688e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
